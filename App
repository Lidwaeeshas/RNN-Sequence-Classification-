import pandas as pd
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader,random_split, Dataset
from transformers import AutoTokenizer
from sklearn.preprocessing import LabelEncoder
from collections import Counter
from sklearn.metrics import accuracy_score,f1_score,recall_score, precision_score



path = "/kaggle/input/global-crocodile-species-dataset"
csv = os.path.join(path,os.listdir(path)[0])
df = pd.read_csv(csv)
inputs= df["Country/Region"] + " " + df["Habitat Type"] + " " + df["Scientific Name"] + " " + df["Family"]
outputs = df["Common Name"]
counter = Counter(outputs)
outputs = LabelEncoder().fit_transform(outputs)
df["inputs"] = inputs
data = df["inputs"].tolist()

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")


class myData(Dataset):
    def __init__(self,x,y,tokenizer):
        self.x = x
        self.y = y
        self.tokenizer = tokenizer
    def __len__(self):
        return len(self.x)
    def __getitem__(self,idx):
        encodings = self.tokenizer(self.x[idx],
                              padding = "max_length",
                              truncation = True,
                              return_tensors = "pt",
                               max_length = 32)
        return encodings["input_ids"].squeeze(), torch.tensor(self.y[idx],dtype = torch.long)





dataset = myData(data,outputs,tokenizer)

class myNeural(nn.Module):
    def __init__(self,vocab_size):
        super().__init__()
        self.lstm = nn.LSTM(input_size = 50,
                            hidden_size = 64,
                            dropout = 0.3,
                            num_layers = 2,
                            batch_first = True)
        self.embed = nn.Embedding(vocab_size,50)
        self.fc = nn.Linear(64,18)
    def forward(self,x):
        x = self.embed(x)
        x,(h_n,c_n) = self.lstm(x)
        x = self.fc(h_n[-1])
        return x

vocab_size = tokenizer.vocab_size
model = myNeural(vocab_size)
optimizer = torch.optim.Adam(model.parameters(),lr = 1e-3)
loss_fn = nn.CrossEntropyLoss()
scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size = 100,gamma = 0.1)

train_size = int(0.8*(len(dataset)))
test_size = len(dataset)-train_size

torch.seed()
train_data,test_data = random_split(dataset,[train_size,test_size])
train_loader = DataLoader(train_data,batch_size = 32,shuffle = True)
test_loader = DataLoader(test_data,batch_size = 32,shuffle = True)

def train(model,loader,optimizer = None,scheduler = None,epochs = 2):
    loss_fn = nn.CrossEntropyLoss()
    if not optimizer:
        optimizer = torch.optim.Adam(model.parameters(),lr = 1e-3)
    if not scheduler:
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size = 100,gamma = 0.1)
    print("training started ðŸš€")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    counting = 1
    for epoch in range(epochs):
        count = 0
        for x,y in loader:
            count += 1
            x = x.to(device)
            y = y.to(device)
            optimizer.zero_grad()
            out = model(x)
            loss = loss_fn(out,y)
            if count %100 == 0:
                print(f"loss at epoch {epoch} is {loss.item():.3f} at {counting}")
                counting += 1
            loss.backward()
            optimizer.step()
    scheduler.step()
    print("training is done âœ…")


def evaluation(model,loader):
    model.eval()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    pred = []
    true = []
    for x,y in loader:
        x = x.to(device)
        y = y.to(device)
        true.extend(y.cpu().numpy())
        with torch.no_grad():
        	out = model(x)
        	prob = nn.functional.softmax(out,dim = 1)
        	logit = torch.argmax(prob,dim = 1)
        pred.extend(logit.cpu().numpy())
    accuracy = accuracy_score(pred,true)
    f1 = f1_score(pred,true, average = "macro")
    precision = precision_score(pred,true,average = "macro")
    recall = recall_score(pred,true,average = "macro")
    return {"accuracy": accuracy,"f1_score":f1,
           "precision": precision,"recall":recall}
train(model,train_loader)
evaluation(model,test_loader)
